{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key exists and begins sk-\n",
      "Groq API Key exists and begins gsk_\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you approach reconciling the ethical implications of artificial intelligence in decision-making processes that affect human lives, while balancing innovation, accountability, and public trust?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Redesigning human society to maximize individual happiness and collective well-being involves establishing foundational principles that promote both personal fulfillment and community responsibility. Here are several principles and approaches to address potential conflicts between individual and collective interests:\n",
       "\n",
       "### Foundational Principles\n",
       "\n",
       "1. **Value of Individual Autonomy**:\n",
       "   - Encourage individual freedom while ensuring that this freedom does not infringe on others' rights. Promote self-determination, enabling individuals to pursue their own paths to happiness.\n",
       "\n",
       "2. **Interdependence and Community Engagement**:\n",
       "   - Foster a sense of community and interdependence. Encourage collaborative living and problem-solving, highlighting how individual well-being is intertwined with collective health.\n",
       "\n",
       "3. **Equity and Fairness**:\n",
       "   - Establish systems to ensure equitable access to resources, opportunities, and rights. Promote social justice and inclusivity, as a fair society enhances collective trust and well-being.\n",
       "\n",
       "4. **Sustainable Development**:\n",
       "   - Prioritize environmental sustainability to secure a healthy planet for future generations. Collective well-being is rooted in environmental health, which in turn supports individual happiness.\n",
       "\n",
       "5. **Lifelong Learning and Personal Growth**:\n",
       "   - Create a culture that values education, curiosity, and personal development. Support systems for continuous learning help individuals explore their potential while benefiting society with enhanced skills and creativity.\n",
       "\n",
       "6. **Health and Well-being**:\n",
       "   - Invest in universal healthcare and mental health support, recognizing that physical and psychological well-being are foundational to both personal happiness and societal productivity.\n",
       "\n",
       "7. **Participatory Governance**:\n",
       "   - Encourage democratic systems that allow for broad participation in decision-making. Utilize deliberative democracy approaches to balance collective interests with individual voices.\n",
       "\n",
       "8. **Empathy and Compassion**:\n",
       "   - Promote empathy as a core value in society. Encourage individuals to consider the perspectives and needs of others, creating a culture where collective concerns are acknowledged and prioritized.\n",
       "\n",
       "### Addressing Conflicts Between Individual and Collective Interests\n",
       "\n",
       "1. **Conflict Resolution Mechanisms**:\n",
       "   - Develop transparent and fair dispute resolution processes that consider both individual and collective needs. Emphasize dialogue and negotiation to reach mutually beneficial outcomes.\n",
       "\n",
       "2. **Education on Collective Responsibility**:\n",
       "   - Educate individuals about the benefits of collective action and the importance of looking beyond individual desires for the greater good. Frames of reference can shape perspectives on what constitutes personal and collective interests.\n",
       "\n",
       "3. **Flexible Social Norms**:\n",
       "   - Accept that social norms must adapt to new circumstances. Create space for individual expression while reinforcing the importance of collective values in specific contexts, such as public health and safety.\n",
       "\n",
       "4. **Reward Systems for Collective Engagement**:\n",
       "   - Implement systems that reward individuals for engaging in collective efforts (e.g., community service, civic participation). This can create positive reinforcement for prioritizing community over individual gain.\n",
       "\n",
       "5. **Balancing Independence with Interdependence**:\n",
       "   - Promote systems that allow individuals to thrive independently while acknowledging their contributions to and reliance on the collective. Highlight stories of individuals whose success is linked to community support.\n",
       "\n",
       "6. **Fiscal Strategies that Promote Redistribution**:\n",
       "   - Create economic mechanisms, such as progressive taxation, that redistribute resources in a way that enhances both individual opportunity and collective welfare, mitigating the risk of individuals prioritizing self-interest at the expense of the community.\n",
       "\n",
       "7. **Encouraging Cooperative Ventures**:\n",
       "   - Support the formation of cooperatives and collaborative businesses that empower individuals while functioning within a framework that serves the collective good, demonstrating that individual success can stem from cooperative effort.\n",
       "\n",
       "By integrating these principles and strategies, a redesigned society could function more harmoniously, ensuring that individual aspirations align with the broader goals of collective well-being, ultimately fostering a more contented and thriving community."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "\"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mclaude-3-7-sonnet-latest\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m claude = Anthropic()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m response = \u001b[43mclaude\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m answer = response.content[\u001b[32m0\u001b[39m].text\n\u001b[32m      9\u001b[39m display(Markdown(answer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/anthropic/_utils/_utils.py:283\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    281\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/anthropic/resources/messages/messages.py:978\u001b[39m, in \u001b[36mMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, service_tier, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m    972\u001b[39m     warnings.warn(\n\u001b[32m    973\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    974\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    975\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    976\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop_sequences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthinking\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsStreaming\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMessageCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1314\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1302\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1309\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1310\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1311\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1312\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1313\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m options = \u001b[38;5;28mself\u001b[39m._prepare_options(options)\n\u001b[32m   1022\u001b[39m remaining_retries = max_retries - retries_taken\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_request(request)\n\u001b[32m   1026\u001b[39m kwargs: HttpxSendArgs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:506\u001b[39m, in \u001b[36mBaseClient._build_request\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    503\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    504\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected JSON data type, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(json_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, cannot merge with `extra_body`\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m headers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m params = _merge_mappings(\u001b[38;5;28mself\u001b[39m.default_query, options.params)\n\u001b[32m    508\u001b[39m content_type = headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:447\u001b[39m, in \u001b[36mBaseClient._build_headers\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    437\u001b[39m custom_headers = options.headers \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    438\u001b[39m headers_dict = _merge_mappings(\n\u001b[32m    439\u001b[39m     {\n\u001b[32m    440\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mx-stainless-timeout\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(options.timeout.read)\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m     custom_headers,\n\u001b[32m    446\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[38;5;66;03m# headers are case-insensitive while dictionaries are not.\u001b[39;00m\n\u001b[32m    450\u001b[39m headers = httpx.Headers(headers_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/anthropic/_client.py:196\u001b[39m, in \u001b[36mAnthropic._validate_headers\u001b[39m\u001b[34m(self, headers, custom_headers)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(custom_headers.get(\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m), Omit):\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    197\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    198\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\""
     ]
    }
   ],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, if I were to redesign human society from scratch with the goal of maximizing both individual happiness and collective well-being, it would be a massive undertaking built upon a foundation of interconnected principles. Here's my attempt at outlining the key aspects:\n",
       "\n",
       "**I. Foundational Principles:**\n",
       "\n",
       "*   **Universal Basic Dignity and Rights:**\n",
       "    *   **Inherent Worth:** Every individual is inherently valuable and deserves respect, regardless of their abilities, beliefs, background, or any other factor.\n",
       "    *   **Fundamental Rights:** Guaranteed access to basic needs (food, water, shelter, healthcare, education), freedom of expression, freedom of association, freedom from violence, and access to justice.  These rights are not privileges granted by the state but inherent entitlements.\n",
       "    *   **Focus on Capabilities:**  Promote individual capabilities (as in Amartya Sen's Capability Approach) by providing resources and opportunities for people to develop their potential and live fulfilling lives.\n",
       "\n",
       "*   **Empathy, Compassion, and Connection:**\n",
       "    *   **Cultivation of Empathy:** Education and social structures that foster empathy and understanding for others, including those with different backgrounds and perspectives.\n",
       "    *   **Strong Social Bonds:**  Encourage strong communities and social connections through shared activities, collaborative projects, and platforms for communication and mutual support.\n",
       "    *   **Altruism and Cooperation:**  Promote altruistic behavior and cooperative problem-solving through positive reinforcement and social norms.\n",
       "\n",
       "*   **Sustainability and Stewardship:**\n",
       "    *   **Ecological Responsibility:**  Recognize that human well-being is inextricably linked to the health of the planet.  Prioritize sustainable practices, resource conservation, and the protection of biodiversity.\n",
       "    *   **Long-Term Vision:**  Make decisions with a long-term perspective, considering the impact on future generations.\n",
       "    *   **Circular Economy:**  Shift away from linear \"take-make-dispose\" models to a circular economy that minimizes waste and maximizes resource utilization.\n",
       "\n",
       "*   **Knowledge, Learning, and Growth:**\n",
       "    *   **Universal Education:**  Provide free, high-quality education from early childhood through adulthood, emphasizing critical thinking, creativity, and lifelong learning.\n",
       "    *   **Open Access to Information:**  Promote open access to knowledge and information, fostering innovation and empowering individuals to make informed decisions.\n",
       "    *   **Scientific Inquiry:**  Support scientific research and evidence-based decision-making, recognizing the importance of knowledge for progress.\n",
       "\n",
       "*   **Empowerment and Participation:**\n",
       "    *   **Decentralized Governance:**  Emphasize participatory democracy and decentralized decision-making, empowering individuals and communities to shape their own lives.\n",
       "    *   **Transparency and Accountability:**  Ensure transparency and accountability in all aspects of governance and public life.\n",
       "    *   **Economic Empowerment:**  Create economic systems that provide opportunities for all individuals to participate and benefit from economic growth.\n",
       "\n",
       "**II. Addressing Conflicts Between Individual and Collective Interests:**\n",
       "\n",
       "This is the core challenge.  Here's how I'd approach it:\n",
       "\n",
       "1.  **Prioritize Basic Needs and Rights:** Individual freedoms shouldn't come at the expense of someone else's basic needs or rights. The collective has a responsibility to ensure everyone's fundamental rights are met.\n",
       "\n",
       "2.  **Define Harm Clearly:** Define harm to others (physical, emotional, economic, environmental) very clearly and precisely. Restrictions on individual freedom should only be justified when there's a substantial risk of harm to others.\n",
       "\n",
       "3.  **Proportionality:** Any restrictions on individual freedoms for the sake of the collective must be proportional to the potential harm being prevented.  The least restrictive means necessary should be used.\n",
       "\n",
       "4.  **Transparency and Deliberation:** Decisions that affect individual freedoms should be made through transparent and deliberative processes, involving input from all stakeholders.\n",
       "\n",
       "5.  **Compensation and Mitigation:**  When collective interests require individuals to make sacrifices, provide compensation or mitigation measures to minimize the burden on those individuals.\n",
       "\n",
       "6.  **Focus on Positive Sum Solutions:**  Strive for solutions that benefit both individuals and the collective whenever possible.  For example, investing in renewable energy creates jobs (individual benefit) while reducing pollution (collective benefit).\n",
       "\n",
       "7.  **Education in Ethics and Civic Responsibility:** Teach ethical reasoning, civic responsibility, and the importance of balancing individual rights with collective obligations.\n",
       "\n",
       "8.  **Dynamic Adaptation:**  Recognize that societal values and priorities may evolve over time.  Establish mechanisms for ongoing dialogue and adaptation to ensure that the balance between individual and collective interests remains fair and just.\n",
       "\n",
       "**III. Key Societal Structures:**\n",
       "\n",
       "*   **Governance:** A multi-layered, participatory democratic system with a focus on direct democracy at the local level and representative democracy at higher levels.  Strong emphasis on transparency, accountability, and citizen oversight.\n",
       "*   **Economy:** A mixed economy that combines elements of market capitalism with social safety nets, worker cooperatives, and community-based enterprises. Focus on sustainable development, equitable distribution of wealth, and meaningful work.\n",
       "*   **Education:** A lifelong learning system that emphasizes critical thinking, creativity, collaboration, and social-emotional development.  Personalized learning pathways tailored to individual needs and interests.\n",
       "*   **Healthcare:** A universal healthcare system that provides access to high-quality medical care for all, regardless of their ability to pay. Emphasis on preventative care and mental health.\n",
       "*   **Justice System:** A restorative justice system that focuses on repairing harm, rehabilitating offenders, and preventing future crime.  Emphasis on mediation, conflict resolution, and community involvement.\n",
       "*   **Technology:**  Technology used to enhance human well-being, promote communication and collaboration, and address global challenges.  Careful consideration of ethical implications and potential risks.\n",
       "\n",
       "**IV.  Examples of Balancing Conflicts:**\n",
       "\n",
       "*   **Vaccination:** Mandates for vaccination to protect public health, but with exemptions for legitimate medical or religious reasons.  Emphasis on education and persuasion rather than coercion.\n",
       "*   **Environmental Regulations:** Regulations to protect the environment, but with incentives for businesses to adopt sustainable practices and compensation for individuals or businesses that are negatively affected.\n",
       "*   **Taxation:** Progressive taxation to fund public services, but with safeguards to ensure that taxes are fair and equitable and that the burden on low-income individuals is minimized.\n",
       "*   **Freedom of Speech:** Protection of freedom of speech, but with limitations on speech that incites violence, defamation, or hate speech.\n",
       "\n",
       "**V. Ongoing Evaluation and Adjustment:**\n",
       "\n",
       "The most important aspect of this system is that it would be subject to continuous evaluation and adjustment.  Regular surveys, public forums, and expert consultations would be used to assess the effectiveness of policies and programs and to identify areas where improvements are needed.\n",
       "\n",
       "**Challenges and Considerations:**\n",
       "\n",
       "*   **Implementation:** The sheer complexity of implementing such a radical redesign is immense.\n",
       "*   **Resistance to Change:**  Entrenched interests and resistance to change would be significant obstacles.\n",
       "*   **Unforeseen Consequences:**  Any large-scale societal change can have unintended consequences.\n",
       "*   **Cultural Diversity:** How to implement these principles in a way that respects and celebrates cultural diversity is a crucial question.\n",
       "\n",
       "This is, of course, a very high-level overview.  The specific details of how these principles would be implemented would need to be worked out through ongoing dialogue and experimentation. But the core idea is to create a society that values both individual flourishing and collective well-being, recognizing that these two goals are ultimately intertwined.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIStatusError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m deepseek = OpenAI(api_key=deepseek_api_key, base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.deepseek.com/v1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mdeepseek-chat\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mdeepseek\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m answer = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m      7\u001b[39m display(Markdown(answer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAPIStatusError\u001b[39m: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
     ]
    }
   ],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach that balances innovation, accountability, and public trust. Here's a comprehensive framework to address these challenges:\n",
       "\n",
       "**Establish Ethical Guidelines and Principles**\n",
       "\n",
       "1. **Develop and adopt industry-wide ethical standards**: Encourage collaboration among stakeholders, including technologists, ethicists, policymakers, and civil society, to establish guidelines for AI development and deployment.\n",
       "2. **Define principles for AI decision-making**: Establish principles that prioritize fairness, transparency, accountability, and respect for human rights and dignity.\n",
       "3. **Incorporate human values**: Embed human values, such as empathy, kindness, and respect for human life, into AI systems to ensure they align with societal norms.\n",
       "\n",
       "**Ensure Transparency and Explainability**\n",
       "\n",
       "1. **.Transparent AI systems**: Design AI systems that provide clear explanations for their decisions and actions, enabling humans to understand and trust their outputs.\n",
       "2. **Model interpretability**: Develop techniques to interpret and analyze AI models, allowing stakeholders to identify biases, errors, or inconsistencies.\n",
       "3. **Data provenance**: Ensure that data used to train and validate AI systems is transparent, accurate, and unbiased.\n",
       "\n",
       "**Accountability and Oversight**\n",
       "\n",
       "1. **Regulatory frameworks**: Establish regulatory frameworks that hold developers, deployers, and users of AI systems accountable for their actions and decisions.\n",
       "2. **Independent review and audit**: Implement independent review and audit processes to ensure AI systems are functioning as intended and meeting ethical standards.\n",
       "3. **Redress mechanisms**: Establish mechanisms for reporting and addressing errors, biases, or harms caused by AI systems.\n",
       "\n",
       "**Public Engagement and Education**\n",
       "\n",
       "1. **Public awareness and education**: Educate the public about the benefits and risks of AI, as well as its limitations and potential biases.\n",
       "2. **Stakeholder engagement**: Engage with diverse stakeholders, including civil society, academia, and industry, to ensure that AI development and deployment reflect societal values and concerns.\n",
       "3. **Inclusive decision-making**: Involve diverse perspectives and voices in AI decision-making processes to ensure that they are representative of the populations they affect.\n",
       "\n",
       "**Innovation and R&D**\n",
       "\n",
       "1. **Encourage responsible AI research**: Support research that focuses on developing AI systems that prioritize human well-being, fairness, and transparency.\n",
       "2. **Invest in AI for social good**: Fund AI projects that address pressing social challenges, such as healthcare, education, and environmental sustainability.\n",
       "3. **Continuous monitoring and evaluation**: Regularly assess the impact of AI systems on human lives and societies, and adjust development and deployment strategies accordingly.\n",
       "\n",
       "**Balancing Innovation, Accountability, and Public Trust**\n",
       "\n",
       "1. **Collaborative governance**: Foster collaboration among stakeholders to ensure that AI development and deployment are aligned with societal values and priorities.\n",
       "2. **Risk-benefit analysis**: Conduct thorough risk-benefit analyses to weigh the potential benefits of AI against potential risks and harms.\n",
       "3. **Regular review and revision**: Regularly review and revise ethical guidelines, principles, and regulations to reflect emerging challenges and concerns.\n",
       "\n",
       "By following this framework, we can balance innovation, accountability, and public trust in AI development and deployment, ultimately ensuring that AI systems are designed to benefit human lives and society as a whole."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest  \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100%  2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100%  1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100%  7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100%  6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100%    96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100%   561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach. Here are some steps I would take to balance innovation, accountability, and public trust:\n",
       "\n",
       "1. Establish clear guidelines and regulations: Develop and enforce strict guidelines and regulations that ensure AI systems are transparent, explainable, and fair. This includes establishing clear standards for data collection, processing, and analysis.\n",
       "2. Conduct thorough risk assessments: Perform comprehensive risk assessments to identify potential biases, errors, or unintended consequences of AI decision-making processes. This helps to mitigate risks and ensure that AI systems are designed with safety and reliability in mind.\n",
       "3. Foster transparency and explainability: Develop techniques for explaining the reasoning behind AI decisions, such as model interpretability, feature attribution, or decision trees. This enables humans to understand how AI arrived at its conclusions and identify potential biases.\n",
       "4. Ensure accountability: Establish accountable frameworks for AI developers, users, and policymakers. This includes setting clear expectations for responsibility, oversight, and consequences for non-compliance with regulations and guidelines.\n",
       "5. Encourage human-AI collaboration: Develop systems that facilitate collaborative decision-making between humans and AI systems. This enables humans to provide context, guidance, and oversight, ensuring that AI decisions align with human values.\n",
       "6. Invest in education and research: Support ongoing education and research to develop the skills and knowledge needed for effective AI ethics. This includes teaching stakeholders the importance of bias awareness, fairness, accountability, and transparency in AI system design and deployment.\n",
       "7. Engage with diverse stakeholders: Involve representatives from various stakeholders, including civil society, industries, and policymakers, to ensure that diverse perspectives are reflected in AI decision-making processes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llama-3.3-70b-versatile', 'llama3.2', 'llama3.2', 'llama3.2', 'llama3.2']\n",
      "[\"Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach that balances innovation, accountability, and public trust. Here's a comprehensive framework to address these challenges:\\n\\n**Establish Ethical Guidelines and Principles**\\n\\n1. **Develop and adopt industry-wide ethical standards**: Encourage collaboration among stakeholders, including technologists, ethicists, policymakers, and civil society, to establish guidelines for AI development and deployment.\\n2. **Define principles for AI decision-making**: Establish principles that prioritize fairness, transparency, accountability, and respect for human rights and dignity.\\n3. **Incorporate human values**: Embed human values, such as empathy, kindness, and respect for human life, into AI systems to ensure they align with societal norms.\\n\\n**Ensure Transparency and Explainability**\\n\\n1. **.Transparent AI systems**: Design AI systems that provide clear explanations for their decisions and actions, enabling humans to understand and trust their outputs.\\n2. **Model interpretability**: Develop techniques to interpret and analyze AI models, allowing stakeholders to identify biases, errors, or inconsistencies.\\n3. **Data provenance**: Ensure that data used to train and validate AI systems is transparent, accurate, and unbiased.\\n\\n**Accountability and Oversight**\\n\\n1. **Regulatory frameworks**: Establish regulatory frameworks that hold developers, deployers, and users of AI systems accountable for their actions and decisions.\\n2. **Independent review and audit**: Implement independent review and audit processes to ensure AI systems are functioning as intended and meeting ethical standards.\\n3. **Redress mechanisms**: Establish mechanisms for reporting and addressing errors, biases, or harms caused by AI systems.\\n\\n**Public Engagement and Education**\\n\\n1. **Public awareness and education**: Educate the public about the benefits and risks of AI, as well as its limitations and potential biases.\\n2. **Stakeholder engagement**: Engage with diverse stakeholders, including civil society, academia, and industry, to ensure that AI development and deployment reflect societal values and concerns.\\n3. **Inclusive decision-making**: Involve diverse perspectives and voices in AI decision-making processes to ensure that they are representative of the populations they affect.\\n\\n**Innovation and R&D**\\n\\n1. **Encourage responsible AI research**: Support research that focuses on developing AI systems that prioritize human well-being, fairness, and transparency.\\n2. **Invest in AI for social good**: Fund AI projects that address pressing social challenges, such as healthcare, education, and environmental sustainability.\\n3. **Continuous monitoring and evaluation**: Regularly assess the impact of AI systems on human lives and societies, and adjust development and deployment strategies accordingly.\\n\\n**Balancing Innovation, Accountability, and Public Trust**\\n\\n1. **Collaborative governance**: Foster collaboration among stakeholders to ensure that AI development and deployment are aligned with societal values and priorities.\\n2. **Risk-benefit analysis**: Conduct thorough risk-benefit analyses to weigh the potential benefits of AI against potential risks and harms.\\n3. **Regular review and revision**: Regularly review and revise ethical guidelines, principles, and regulations to reflect emerging challenges and concerns.\\n\\nBy following this framework, we can balance innovation, accountability, and public trust in AI development and deployment, ultimately ensuring that AI systems are designed to benefit human lives and society as a whole.\", \"Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a holistic approach that balances innovation, accountability, and public trust. Here's a step-by-step guide to help achieve this reconciliation:\\n\\n1. **Establish a Regulatory Framework**: Develop and implement a regulatory framework that addresses AI-related issues, such as data protection, transparency, and accountability. This framework should be technology-agnostic, allowing for adaptability as new technologies emerge.\\n2. **Human-Centric Design**: Ensure that AI systems are designed with human values and ethics at their core. This includes incorporating diverse perspectives, ensuring explainability, and prioritizing user well-being.\\n3. **Transparency and Explainability**: Develop techniques to provide insights into AI decision-making processes, such as model interpretability, feature attribution, and transparency in data sources. This helps build trust and accountability.\\n4. **Auditing and Testing**: Regularly audit and test AI systems for bias, vulnerability, and performance issues. This includes evaluating the impact of biases on individual outcomes and societal consequences.\\n5. **Collaboration and Engagement**: Foster collaboration between stakeholders, including policymakers, industry experts, academics, civil society organizations, and community representatives. Ensure that diverse groups are involved in decision-making processes to represent various interests and values.\\n6. **Accountability Mechanisms**: Establish accountability mechanisms, such as complaints procedures, dispute resolution systems, and whistleblower protection policies. Ensure transparency and consequences for non-compliance with standards of AI development and deployment.\\n7. **Public Engagement and Education**: Engage the public in discussions about AI-related issues, ensuring that they understand the potential benefits and challenges. Encourage education and awareness programs to address misconceptions and foster a nuanced understanding of AI.\\n8. **Value Alignment**: Ensure that AI systems align with societal values, such as fairness, equal access, and respect for human rights. This includes considering ethical considerations like human dignity, privacy, and freedom from discrimination.\\n9. **Continuous Monitoring and Evaluation**: Regularly monitor and evaluate AI performance, identifying areas for improvement and ensuring the continued effectiveness of regulations and accountability mechanisms.\\n10. **Industry-Led Self-Regulation**: Encourage industry-led self-regulation through initiatives that promote best practices, voluntary standards, and continuous monitoring.\\n\\n**Key Principles**\\n\\n1. **Respect for Human Rights**: Prioritize respect for human rights, including dignity, autonomy, and freedom from discrimination or harm.\\n2. **Fairness and Non-Discrimination**: Ensure AI systems operate fairly and avoid discrimination based on personal characteristics, such as race, ethnicity, gender, sexuality, or socio-economic status.\\n3. **Transparency and Accountability**: Promote transparency in AI decision-making processes, with clear explanations of algorithms used and accountability mechanisms for any negative consequences.\\n\\n**Best Practices**\\n\\n1. **Use Open-Source Algorithms**: Develop and use open-source algorithms to make them more transparent, auditable, and maintainable.\\n2. **Employ Ethics-Based Design Principles**: Integrate ethics-based design principles into AI development processes, ensuring that value alignment with human rights and societal values is upheld.\\n3. **Conduct Regular Impact Assessments**: Conduct regular impact assessments to identify potential risks and challenges associated with AI system deployment.\\n\\nBy following these guidelines, incorporating industry-led self-regulation, and promoting continuous monitoring and evaluation, we can ensure that the benefits of AI innovation are balanced against public trust, accountability, and respect for human rights.\", 'Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach. Here are some steps to balance innovation, accountability, and public trust:\\n\\n1. **Establish a framework for AI ethics**: Develop a set of principles and guidelines for AI development, deployment, and use, that prioritizes human well-being and rights. These principles should be aligned with international human rights standards and reflect global values.\\n2. **Collaborative governance**: Foster collaboration among governments, industries, civil society organizations, academia, and experts to ensure diverse perspectives and interests are represented in AI policy-making. This includes creating independent regulatory agencies or oversight bodies that can monitor AI development and deployment.\\n3. **Human-centered design**: Ensure that AI systems are designed with human values and needs in mind. This involves engaging with diverse stakeholders, including users, to understand their concerns, preferences, and expectations.\\n4. **Transparent decision-making processes**: Develop explainable AI (XAI) techniques that provide insights into AI-driven decisions. This enables humans to understand how AI systems arrive at conclusions and ensures transparency in decision-making.\\n5. **Accountability mechanisms**: Establish accountability frameworks for organizations and individuals involved in AI development and deployment. This includes mechanisms for reporting, investigation, and addressing adverse consequences of AI-related decisions.\\n6. **Regular audits and assessments**: Conduct regular reviews of AI systems to identify biases, inaccuracies, or other potential ethical issues. These assessments should be based on a risk-based approach and involve diverse stakeholders.\\n7. **Education and awareness-raising**: Provide education and awareness programs for stakeholders, including developers, users, policymakers, and the general public, about the potential risks and benefits of AI.\\n8. **Diversity and inclusion in decision-making**: Ensure that decision-making bodies involved in AI development and deployment have diverse representation of groups with different perspectives, experiences, and interests.\\n9. **Inclusive public engagement**: Engage with diverse stakeholders, including marginalized communities, to understand their concerns, needs, and aspirations related to AI. This includes facilitating open dialogue, feedback mechanisms, and opportunities for participation.\\n10. **Continuous monitoring and evaluation**: Regularly monitor the impact of AI on human lives and society, and continuously evaluate and improve AI systems to ensure they align with evolving social values and norms.\\n\\nAdditionally, consider implementing the following principles:\\n\\n1. **Proportionality**: Ensure that AI decisions are proportionate to their impact on individuals and communities.\\n2. **Necessity**: Only use AI when necessary, and only for purposes that outweigh potential risks.\\n3. **Precaution**: Implement safeguard mechanisms to mitigate potential harm from AI-driven decisions.\\n4. **Transparency**: Provide clear explanations of AI-driven decisions to users and stakeholders.\\n5. **Responsibility**: Hold individuals and organizations accountable for AI-related consequences.\\n\\nBy embracing these principles and approaches, we can ensure that AI innovations are developed and deployed in ways that promote public trust, accountability, and human well-being.', 'Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach that balances innovation, accountability, and public trust. Here\\'s a framework to consider:\\n\\n1. **Establish clear goals and principles**: Develop a set of clear goals, values, and principles for AI development and deployment. These should include respect for human rights, dignity, and well-being.\\n2. **Design for transparency and explainability**: Implement mechanisms that provide insight into AI decision-making processes, ensuring that stakeholders understand how decisions are made. Techniques like model interpretability, feature attribution, and decision analytics can help achieve this.\\n3. **Prioritize fairness and equity**: Ensure that AI systems are designed to promote fairness and equity in their decision-making processes. This includes avoiding biases, protecting vulnerable groups, and addressing discriminatory outcomes.\\n4. **Implement robust accountability frameworks**: Establish mechanisms for accountability, such as independent review boards, auditor oversight, or internal auditing, to ensure that AI decisions are reviewed and justified.\\n5. **Foster public engagement and participation**: Encourage open dialogue between the public, stakeholders, and AI developers to understand concerns, gather feedback, and develop solutions that meet societal needs.\\n6. **Invest in AI literacy and education**: Educate the general public, researchers, and industry professionals about the benefits, risks, and limitations of AI, as well as its applications and potential biases.\\n7. **Monitor and evaluate AI performance**: Regularly assess the performance of AI systems to ensure that they are meeting their intended goals and not causing harm. This can involve benchmarking against human decision-making processes or using robust evaluation metrics.\\n8. **Encourage multidisciplinary research and collaboration**: Foster partnerships between researchers, policymakers, industry experts, and civil society organizations to develop a deeper understanding of AI\\'s impact and develop evidence-based solutions.\\n9. **Implement governance frameworks**: Establish regulatory bodies, standards organizations, or certification programs that can ensure AI systems are designed and deployed responsibly.\\n10. **Emphasize human-centered design principles**: Incorporate human values, ethics, and social norms into AI system design to prioritize the well-being of individuals and communities.\\n\\nTo balance these competing interests, consider a \"Design for Responsibility\" approach:\\n\\n1. Identify potential harms or risks associated with AI decision-making processes that affect human lives.\\n2. Develop mechanisms to mitigate or prevent those harms, while promoting innovation and accountability.\\n3. Implement monitoring and evaluation frameworks to track the performance of AI systems over time.\\n4. Foster ongoing dialogue between stakeholders to identify emerging challenges and develop solutions.\\n\\nBy adopting this framework, organizations can ensure that AI decision-making processes prioritize human values, promote public trust, and balance innovation with ethical considerations.\\n\\nKey questions to explore:\\n\\n1. How can we measure the impact of AI on human lives and decisions?\\n2. Can we develop algorithms that truly prioritize fairness, transparency, and accountability?\\n3. How do we protect vulnerable groups from AI-driven biases and discriminatory outcomes?\\n4. Can machine learning models be used to mitigate societal harm or ensure social justice?\\n\\nTo drive meaningful progress, consider these best practice principles:\\n\\n1. Prioritize open collaboration between stakeholders.\\n2. Foster a culture of responsibility within organizations.\\n3. Invest in educational programs for researchers and industry professionals.\\n4. Encourage public awareness campaigns about AI potential risks and benefits.\\n\\nBy emphasizing responsibility, transparency, accountability, and human-centered design, we can harness the power of AI to improve decision-making processes that impact people\\'s lives while minimizing associated risks.', 'Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach. Here are some steps I would take to balance innovation, accountability, and public trust:\\n\\n1. Establish clear guidelines and regulations: Develop and enforce strict guidelines and regulations that ensure AI systems are transparent, explainable, and fair. This includes establishing clear standards for data collection, processing, and analysis.\\n2. Conduct thorough risk assessments: Perform comprehensive risk assessments to identify potential biases, errors, or unintended consequences of AI decision-making processes. This helps to mitigate risks and ensure that AI systems are designed with safety and reliability in mind.\\n3. Foster transparency and explainability: Develop techniques for explaining the reasoning behind AI decisions, such as model interpretability, feature attribution, or decision trees. This enables humans to understand how AI arrived at its conclusions and identify potential biases.\\n4. Ensure accountability: Establish accountable frameworks for AI developers, users, and policymakers. This includes setting clear expectations for responsibility, oversight, and consequences for non-compliance with regulations and guidelines.\\n5. Encourage human-AI collaboration: Develop systems that facilitate collaborative decision-making between humans and AI systems. This enables humans to provide context, guidance, and oversight, ensuring that AI decisions align with human values.\\n6. Invest in education and research: Support ongoing education and research to develop the skills and knowledge needed for effective AI ethics. This includes teaching stakeholders the importance of bias awareness, fairness, accountability, and transparency in AI system design and deployment.\\n7. Engage with diverse stakeholders: Involve representatives from various stakeholders, including civil society, industries, and policymakers, to ensure that diverse perspectives are reflected in AI decision-making processes.']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: llama-3.3-70b-versatile\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach that balances innovation, accountability, and public trust. Here's a comprehensive framework to address these challenges:\n",
      "\n",
      "**Establish Ethical Guidelines and Principles**\n",
      "\n",
      "1. **Develop and adopt industry-wide ethical standards**: Encourage collaboration among stakeholders, including technologists, ethicists, policymakers, and civil society, to establish guidelines for AI development and deployment.\n",
      "2. **Define principles for AI decision-making**: Establish principles that prioritize fairness, transparency, accountability, and respect for human rights and dignity.\n",
      "3. **Incorporate human values**: Embed human values, such as empathy, kindness, and respect for human life, into AI systems to ensure they align with societal norms.\n",
      "\n",
      "**Ensure Transparency and Explainability**\n",
      "\n",
      "1. **.Transparent AI systems**: Design AI systems that provide clear explanations for their decisions and actions, enabling humans to understand and trust their outputs.\n",
      "2. **Model interpretability**: Develop techniques to interpret and analyze AI models, allowing stakeholders to identify biases, errors, or inconsistencies.\n",
      "3. **Data provenance**: Ensure that data used to train and validate AI systems is transparent, accurate, and unbiased.\n",
      "\n",
      "**Accountability and Oversight**\n",
      "\n",
      "1. **Regulatory frameworks**: Establish regulatory frameworks that hold developers, deployers, and users of AI systems accountable for their actions and decisions.\n",
      "2. **Independent review and audit**: Implement independent review and audit processes to ensure AI systems are functioning as intended and meeting ethical standards.\n",
      "3. **Redress mechanisms**: Establish mechanisms for reporting and addressing errors, biases, or harms caused by AI systems.\n",
      "\n",
      "**Public Engagement and Education**\n",
      "\n",
      "1. **Public awareness and education**: Educate the public about the benefits and risks of AI, as well as its limitations and potential biases.\n",
      "2. **Stakeholder engagement**: Engage with diverse stakeholders, including civil society, academia, and industry, to ensure that AI development and deployment reflect societal values and concerns.\n",
      "3. **Inclusive decision-making**: Involve diverse perspectives and voices in AI decision-making processes to ensure that they are representative of the populations they affect.\n",
      "\n",
      "**Innovation and R&D**\n",
      "\n",
      "1. **Encourage responsible AI research**: Support research that focuses on developing AI systems that prioritize human well-being, fairness, and transparency.\n",
      "2. **Invest in AI for social good**: Fund AI projects that address pressing social challenges, such as healthcare, education, and environmental sustainability.\n",
      "3. **Continuous monitoring and evaluation**: Regularly assess the impact of AI systems on human lives and societies, and adjust development and deployment strategies accordingly.\n",
      "\n",
      "**Balancing Innovation, Accountability, and Public Trust**\n",
      "\n",
      "1. **Collaborative governance**: Foster collaboration among stakeholders to ensure that AI development and deployment are aligned with societal values and priorities.\n",
      "2. **Risk-benefit analysis**: Conduct thorough risk-benefit analyses to weigh the potential benefits of AI against potential risks and harms.\n",
      "3. **Regular review and revision**: Regularly review and revise ethical guidelines, principles, and regulations to reflect emerging challenges and concerns.\n",
      "\n",
      "By following this framework, we can balance innovation, accountability, and public trust in AI development and deployment, ultimately ensuring that AI systems are designed to benefit human lives and society as a whole.\n",
      "Competitor: llama3.2\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a holistic approach that balances innovation, accountability, and public trust. Here's a step-by-step guide to help achieve this reconciliation:\n",
      "\n",
      "1. **Establish a Regulatory Framework**: Develop and implement a regulatory framework that addresses AI-related issues, such as data protection, transparency, and accountability. This framework should be technology-agnostic, allowing for adaptability as new technologies emerge.\n",
      "2. **Human-Centric Design**: Ensure that AI systems are designed with human values and ethics at their core. This includes incorporating diverse perspectives, ensuring explainability, and prioritizing user well-being.\n",
      "3. **Transparency and Explainability**: Develop techniques to provide insights into AI decision-making processes, such as model interpretability, feature attribution, and transparency in data sources. This helps build trust and accountability.\n",
      "4. **Auditing and Testing**: Regularly audit and test AI systems for bias, vulnerability, and performance issues. This includes evaluating the impact of biases on individual outcomes and societal consequences.\n",
      "5. **Collaboration and Engagement**: Foster collaboration between stakeholders, including policymakers, industry experts, academics, civil society organizations, and community representatives. Ensure that diverse groups are involved in decision-making processes to represent various interests and values.\n",
      "6. **Accountability Mechanisms**: Establish accountability mechanisms, such as complaints procedures, dispute resolution systems, and whistleblower protection policies. Ensure transparency and consequences for non-compliance with standards of AI development and deployment.\n",
      "7. **Public Engagement and Education**: Engage the public in discussions about AI-related issues, ensuring that they understand the potential benefits and challenges. Encourage education and awareness programs to address misconceptions and foster a nuanced understanding of AI.\n",
      "8. **Value Alignment**: Ensure that AI systems align with societal values, such as fairness, equal access, and respect for human rights. This includes considering ethical considerations like human dignity, privacy, and freedom from discrimination.\n",
      "9. **Continuous Monitoring and Evaluation**: Regularly monitor and evaluate AI performance, identifying areas for improvement and ensuring the continued effectiveness of regulations and accountability mechanisms.\n",
      "10. **Industry-Led Self-Regulation**: Encourage industry-led self-regulation through initiatives that promote best practices, voluntary standards, and continuous monitoring.\n",
      "\n",
      "**Key Principles**\n",
      "\n",
      "1. **Respect for Human Rights**: Prioritize respect for human rights, including dignity, autonomy, and freedom from discrimination or harm.\n",
      "2. **Fairness and Non-Discrimination**: Ensure AI systems operate fairly and avoid discrimination based on personal characteristics, such as race, ethnicity, gender, sexuality, or socio-economic status.\n",
      "3. **Transparency and Accountability**: Promote transparency in AI decision-making processes, with clear explanations of algorithms used and accountability mechanisms for any negative consequences.\n",
      "\n",
      "**Best Practices**\n",
      "\n",
      "1. **Use Open-Source Algorithms**: Develop and use open-source algorithms to make them more transparent, auditable, and maintainable.\n",
      "2. **Employ Ethics-Based Design Principles**: Integrate ethics-based design principles into AI development processes, ensuring that value alignment with human rights and societal values is upheld.\n",
      "3. **Conduct Regular Impact Assessments**: Conduct regular impact assessments to identify potential risks and challenges associated with AI system deployment.\n",
      "\n",
      "By following these guidelines, incorporating industry-led self-regulation, and promoting continuous monitoring and evaluation, we can ensure that the benefits of AI innovation are balanced against public trust, accountability, and respect for human rights.\n",
      "Competitor: llama3.2\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach. Here are some steps to balance innovation, accountability, and public trust:\n",
      "\n",
      "1. **Establish a framework for AI ethics**: Develop a set of principles and guidelines for AI development, deployment, and use, that prioritizes human well-being and rights. These principles should be aligned with international human rights standards and reflect global values.\n",
      "2. **Collaborative governance**: Foster collaboration among governments, industries, civil society organizations, academia, and experts to ensure diverse perspectives and interests are represented in AI policy-making. This includes creating independent regulatory agencies or oversight bodies that can monitor AI development and deployment.\n",
      "3. **Human-centered design**: Ensure that AI systems are designed with human values and needs in mind. This involves engaging with diverse stakeholders, including users, to understand their concerns, preferences, and expectations.\n",
      "4. **Transparent decision-making processes**: Develop explainable AI (XAI) techniques that provide insights into AI-driven decisions. This enables humans to understand how AI systems arrive at conclusions and ensures transparency in decision-making.\n",
      "5. **Accountability mechanisms**: Establish accountability frameworks for organizations and individuals involved in AI development and deployment. This includes mechanisms for reporting, investigation, and addressing adverse consequences of AI-related decisions.\n",
      "6. **Regular audits and assessments**: Conduct regular reviews of AI systems to identify biases, inaccuracies, or other potential ethical issues. These assessments should be based on a risk-based approach and involve diverse stakeholders.\n",
      "7. **Education and awareness-raising**: Provide education and awareness programs for stakeholders, including developers, users, policymakers, and the general public, about the potential risks and benefits of AI.\n",
      "8. **Diversity and inclusion in decision-making**: Ensure that decision-making bodies involved in AI development and deployment have diverse representation of groups with different perspectives, experiences, and interests.\n",
      "9. **Inclusive public engagement**: Engage with diverse stakeholders, including marginalized communities, to understand their concerns, needs, and aspirations related to AI. This includes facilitating open dialogue, feedback mechanisms, and opportunities for participation.\n",
      "10. **Continuous monitoring and evaluation**: Regularly monitor the impact of AI on human lives and society, and continuously evaluate and improve AI systems to ensure they align with evolving social values and norms.\n",
      "\n",
      "Additionally, consider implementing the following principles:\n",
      "\n",
      "1. **Proportionality**: Ensure that AI decisions are proportionate to their impact on individuals and communities.\n",
      "2. **Necessity**: Only use AI when necessary, and only for purposes that outweigh potential risks.\n",
      "3. **Precaution**: Implement safeguard mechanisms to mitigate potential harm from AI-driven decisions.\n",
      "4. **Transparency**: Provide clear explanations of AI-driven decisions to users and stakeholders.\n",
      "5. **Responsibility**: Hold individuals and organizations accountable for AI-related consequences.\n",
      "\n",
      "By embracing these principles and approaches, we can ensure that AI innovations are developed and deployed in ways that promote public trust, accountability, and human well-being.\n",
      "Competitor: llama3.2\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach that balances innovation, accountability, and public trust. Here's a framework to consider:\n",
      "\n",
      "1. **Establish clear goals and principles**: Develop a set of clear goals, values, and principles for AI development and deployment. These should include respect for human rights, dignity, and well-being.\n",
      "2. **Design for transparency and explainability**: Implement mechanisms that provide insight into AI decision-making processes, ensuring that stakeholders understand how decisions are made. Techniques like model interpretability, feature attribution, and decision analytics can help achieve this.\n",
      "3. **Prioritize fairness and equity**: Ensure that AI systems are designed to promote fairness and equity in their decision-making processes. This includes avoiding biases, protecting vulnerable groups, and addressing discriminatory outcomes.\n",
      "4. **Implement robust accountability frameworks**: Establish mechanisms for accountability, such as independent review boards, auditor oversight, or internal auditing, to ensure that AI decisions are reviewed and justified.\n",
      "5. **Foster public engagement and participation**: Encourage open dialogue between the public, stakeholders, and AI developers to understand concerns, gather feedback, and develop solutions that meet societal needs.\n",
      "6. **Invest in AI literacy and education**: Educate the general public, researchers, and industry professionals about the benefits, risks, and limitations of AI, as well as its applications and potential biases.\n",
      "7. **Monitor and evaluate AI performance**: Regularly assess the performance of AI systems to ensure that they are meeting their intended goals and not causing harm. This can involve benchmarking against human decision-making processes or using robust evaluation metrics.\n",
      "8. **Encourage multidisciplinary research and collaboration**: Foster partnerships between researchers, policymakers, industry experts, and civil society organizations to develop a deeper understanding of AI's impact and develop evidence-based solutions.\n",
      "9. **Implement governance frameworks**: Establish regulatory bodies, standards organizations, or certification programs that can ensure AI systems are designed and deployed responsibly.\n",
      "10. **Emphasize human-centered design principles**: Incorporate human values, ethics, and social norms into AI system design to prioritize the well-being of individuals and communities.\n",
      "\n",
      "To balance these competing interests, consider a \"Design for Responsibility\" approach:\n",
      "\n",
      "1. Identify potential harms or risks associated with AI decision-making processes that affect human lives.\n",
      "2. Develop mechanisms to mitigate or prevent those harms, while promoting innovation and accountability.\n",
      "3. Implement monitoring and evaluation frameworks to track the performance of AI systems over time.\n",
      "4. Foster ongoing dialogue between stakeholders to identify emerging challenges and develop solutions.\n",
      "\n",
      "By adopting this framework, organizations can ensure that AI decision-making processes prioritize human values, promote public trust, and balance innovation with ethical considerations.\n",
      "\n",
      "Key questions to explore:\n",
      "\n",
      "1. How can we measure the impact of AI on human lives and decisions?\n",
      "2. Can we develop algorithms that truly prioritize fairness, transparency, and accountability?\n",
      "3. How do we protect vulnerable groups from AI-driven biases and discriminatory outcomes?\n",
      "4. Can machine learning models be used to mitigate societal harm or ensure social justice?\n",
      "\n",
      "To drive meaningful progress, consider these best practice principles:\n",
      "\n",
      "1. Prioritize open collaboration between stakeholders.\n",
      "2. Foster a culture of responsibility within organizations.\n",
      "3. Invest in educational programs for researchers and industry professionals.\n",
      "4. Encourage public awareness campaigns about AI potential risks and benefits.\n",
      "\n",
      "By emphasizing responsibility, transparency, accountability, and human-centered design, we can harness the power of AI to improve decision-making processes that impact people's lives while minimizing associated risks.\n",
      "Competitor: llama3.2\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach. Here are some steps I would take to balance innovation, accountability, and public trust:\n",
      "\n",
      "1. Establish clear guidelines and regulations: Develop and enforce strict guidelines and regulations that ensure AI systems are transparent, explainable, and fair. This includes establishing clear standards for data collection, processing, and analysis.\n",
      "2. Conduct thorough risk assessments: Perform comprehensive risk assessments to identify potential biases, errors, or unintended consequences of AI decision-making processes. This helps to mitigate risks and ensure that AI systems are designed with safety and reliability in mind.\n",
      "3. Foster transparency and explainability: Develop techniques for explaining the reasoning behind AI decisions, such as model interpretability, feature attribution, or decision trees. This enables humans to understand how AI arrived at its conclusions and identify potential biases.\n",
      "4. Ensure accountability: Establish accountable frameworks for AI developers, users, and policymakers. This includes setting clear expectations for responsibility, oversight, and consequences for non-compliance with regulations and guidelines.\n",
      "5. Encourage human-AI collaboration: Develop systems that facilitate collaborative decision-making between humans and AI systems. This enables humans to provide context, guidance, and oversight, ensuring that AI decisions align with human values.\n",
      "6. Invest in education and research: Support ongoing education and research to develop the skills and knowledge needed for effective AI ethics. This includes teaching stakeholders the importance of bias awareness, fairness, accountability, and transparency in AI system design and deployment.\n",
      "7. Engage with diverse stakeholders: Involve representatives from various stakeholders, including civil society, industries, and policymakers, to ensure that diverse perspectives are reflected in AI decision-making processes.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach that balances innovation, accountability, and public trust. Here's a comprehensive framework to address these challenges:\n",
      "\n",
      "**Establish Ethical Guidelines and Principles**\n",
      "\n",
      "1. **Develop and adopt industry-wide ethical standards**: Encourage collaboration among stakeholders, including technologists, ethicists, policymakers, and civil society, to establish guidelines for AI development and deployment.\n",
      "2. **Define principles for AI decision-making**: Establish principles that prioritize fairness, transparency, accountability, and respect for human rights and dignity.\n",
      "3. **Incorporate human values**: Embed human values, such as empathy, kindness, and respect for human life, into AI systems to ensure they align with societal norms.\n",
      "\n",
      "**Ensure Transparency and Explainability**\n",
      "\n",
      "1. **.Transparent AI systems**: Design AI systems that provide clear explanations for their decisions and actions, enabling humans to understand and trust their outputs.\n",
      "2. **Model interpretability**: Develop techniques to interpret and analyze AI models, allowing stakeholders to identify biases, errors, or inconsistencies.\n",
      "3. **Data provenance**: Ensure that data used to train and validate AI systems is transparent, accurate, and unbiased.\n",
      "\n",
      "**Accountability and Oversight**\n",
      "\n",
      "1. **Regulatory frameworks**: Establish regulatory frameworks that hold developers, deployers, and users of AI systems accountable for their actions and decisions.\n",
      "2. **Independent review and audit**: Implement independent review and audit processes to ensure AI systems are functioning as intended and meeting ethical standards.\n",
      "3. **Redress mechanisms**: Establish mechanisms for reporting and addressing errors, biases, or harms caused by AI systems.\n",
      "\n",
      "**Public Engagement and Education**\n",
      "\n",
      "1. **Public awareness and education**: Educate the public about the benefits and risks of AI, as well as its limitations and potential biases.\n",
      "2. **Stakeholder engagement**: Engage with diverse stakeholders, including civil society, academia, and industry, to ensure that AI development and deployment reflect societal values and concerns.\n",
      "3. **Inclusive decision-making**: Involve diverse perspectives and voices in AI decision-making processes to ensure that they are representative of the populations they affect.\n",
      "\n",
      "**Innovation and R&D**\n",
      "\n",
      "1. **Encourage responsible AI research**: Support research that focuses on developing AI systems that prioritize human well-being, fairness, and transparency.\n",
      "2. **Invest in AI for social good**: Fund AI projects that address pressing social challenges, such as healthcare, education, and environmental sustainability.\n",
      "3. **Continuous monitoring and evaluation**: Regularly assess the impact of AI systems on human lives and societies, and adjust development and deployment strategies accordingly.\n",
      "\n",
      "**Balancing Innovation, Accountability, and Public Trust**\n",
      "\n",
      "1. **Collaborative governance**: Foster collaboration among stakeholders to ensure that AI development and deployment are aligned with societal values and priorities.\n",
      "2. **Risk-benefit analysis**: Conduct thorough risk-benefit analyses to weigh the potential benefits of AI against potential risks and harms.\n",
      "3. **Regular review and revision**: Regularly review and revise ethical guidelines, principles, and regulations to reflect emerging challenges and concerns.\n",
      "\n",
      "By following this framework, we can balance innovation, accountability, and public trust in AI development and deployment, ultimately ensuring that AI systems are designed to benefit human lives and society as a whole.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a holistic approach that balances innovation, accountability, and public trust. Here's a step-by-step guide to help achieve this reconciliation:\n",
      "\n",
      "1. **Establish a Regulatory Framework**: Develop and implement a regulatory framework that addresses AI-related issues, such as data protection, transparency, and accountability. This framework should be technology-agnostic, allowing for adaptability as new technologies emerge.\n",
      "2. **Human-Centric Design**: Ensure that AI systems are designed with human values and ethics at their core. This includes incorporating diverse perspectives, ensuring explainability, and prioritizing user well-being.\n",
      "3. **Transparency and Explainability**: Develop techniques to provide insights into AI decision-making processes, such as model interpretability, feature attribution, and transparency in data sources. This helps build trust and accountability.\n",
      "4. **Auditing and Testing**: Regularly audit and test AI systems for bias, vulnerability, and performance issues. This includes evaluating the impact of biases on individual outcomes and societal consequences.\n",
      "5. **Collaboration and Engagement**: Foster collaboration between stakeholders, including policymakers, industry experts, academics, civil society organizations, and community representatives. Ensure that diverse groups are involved in decision-making processes to represent various interests and values.\n",
      "6. **Accountability Mechanisms**: Establish accountability mechanisms, such as complaints procedures, dispute resolution systems, and whistleblower protection policies. Ensure transparency and consequences for non-compliance with standards of AI development and deployment.\n",
      "7. **Public Engagement and Education**: Engage the public in discussions about AI-related issues, ensuring that they understand the potential benefits and challenges. Encourage education and awareness programs to address misconceptions and foster a nuanced understanding of AI.\n",
      "8. **Value Alignment**: Ensure that AI systems align with societal values, such as fairness, equal access, and respect for human rights. This includes considering ethical considerations like human dignity, privacy, and freedom from discrimination.\n",
      "9. **Continuous Monitoring and Evaluation**: Regularly monitor and evaluate AI performance, identifying areas for improvement and ensuring the continued effectiveness of regulations and accountability mechanisms.\n",
      "10. **Industry-Led Self-Regulation**: Encourage industry-led self-regulation through initiatives that promote best practices, voluntary standards, and continuous monitoring.\n",
      "\n",
      "**Key Principles**\n",
      "\n",
      "1. **Respect for Human Rights**: Prioritize respect for human rights, including dignity, autonomy, and freedom from discrimination or harm.\n",
      "2. **Fairness and Non-Discrimination**: Ensure AI systems operate fairly and avoid discrimination based on personal characteristics, such as race, ethnicity, gender, sexuality, or socio-economic status.\n",
      "3. **Transparency and Accountability**: Promote transparency in AI decision-making processes, with clear explanations of algorithms used and accountability mechanisms for any negative consequences.\n",
      "\n",
      "**Best Practices**\n",
      "\n",
      "1. **Use Open-Source Algorithms**: Develop and use open-source algorithms to make them more transparent, auditable, and maintainable.\n",
      "2. **Employ Ethics-Based Design Principles**: Integrate ethics-based design principles into AI development processes, ensuring that value alignment with human rights and societal values is upheld.\n",
      "3. **Conduct Regular Impact Assessments**: Conduct regular impact assessments to identify potential risks and challenges associated with AI system deployment.\n",
      "\n",
      "By following these guidelines, incorporating industry-led self-regulation, and promoting continuous monitoring and evaluation, we can ensure that the benefits of AI innovation are balanced against public trust, accountability, and respect for human rights.\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach. Here are some steps to balance innovation, accountability, and public trust:\n",
      "\n",
      "1. **Establish a framework for AI ethics**: Develop a set of principles and guidelines for AI development, deployment, and use, that prioritizes human well-being and rights. These principles should be aligned with international human rights standards and reflect global values.\n",
      "2. **Collaborative governance**: Foster collaboration among governments, industries, civil society organizations, academia, and experts to ensure diverse perspectives and interests are represented in AI policy-making. This includes creating independent regulatory agencies or oversight bodies that can monitor AI development and deployment.\n",
      "3. **Human-centered design**: Ensure that AI systems are designed with human values and needs in mind. This involves engaging with diverse stakeholders, including users, to understand their concerns, preferences, and expectations.\n",
      "4. **Transparent decision-making processes**: Develop explainable AI (XAI) techniques that provide insights into AI-driven decisions. This enables humans to understand how AI systems arrive at conclusions and ensures transparency in decision-making.\n",
      "5. **Accountability mechanisms**: Establish accountability frameworks for organizations and individuals involved in AI development and deployment. This includes mechanisms for reporting, investigation, and addressing adverse consequences of AI-related decisions.\n",
      "6. **Regular audits and assessments**: Conduct regular reviews of AI systems to identify biases, inaccuracies, or other potential ethical issues. These assessments should be based on a risk-based approach and involve diverse stakeholders.\n",
      "7. **Education and awareness-raising**: Provide education and awareness programs for stakeholders, including developers, users, policymakers, and the general public, about the potential risks and benefits of AI.\n",
      "8. **Diversity and inclusion in decision-making**: Ensure that decision-making bodies involved in AI development and deployment have diverse representation of groups with different perspectives, experiences, and interests.\n",
      "9. **Inclusive public engagement**: Engage with diverse stakeholders, including marginalized communities, to understand their concerns, needs, and aspirations related to AI. This includes facilitating open dialogue, feedback mechanisms, and opportunities for participation.\n",
      "10. **Continuous monitoring and evaluation**: Regularly monitor the impact of AI on human lives and society, and continuously evaluate and improve AI systems to ensure they align with evolving social values and norms.\n",
      "\n",
      "Additionally, consider implementing the following principles:\n",
      "\n",
      "1. **Proportionality**: Ensure that AI decisions are proportionate to their impact on individuals and communities.\n",
      "2. **Necessity**: Only use AI when necessary, and only for purposes that outweigh potential risks.\n",
      "3. **Precaution**: Implement safeguard mechanisms to mitigate potential harm from AI-driven decisions.\n",
      "4. **Transparency**: Provide clear explanations of AI-driven decisions to users and stakeholders.\n",
      "5. **Responsibility**: Hold individuals and organizations accountable for AI-related consequences.\n",
      "\n",
      "By embracing these principles and approaches, we can ensure that AI innovations are developed and deployed in ways that promote public trust, accountability, and human well-being.\n",
      "\n",
      "# Response from competitor 4\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach that balances innovation, accountability, and public trust. Here's a framework to consider:\n",
      "\n",
      "1. **Establish clear goals and principles**: Develop a set of clear goals, values, and principles for AI development and deployment. These should include respect for human rights, dignity, and well-being.\n",
      "2. **Design for transparency and explainability**: Implement mechanisms that provide insight into AI decision-making processes, ensuring that stakeholders understand how decisions are made. Techniques like model interpretability, feature attribution, and decision analytics can help achieve this.\n",
      "3. **Prioritize fairness and equity**: Ensure that AI systems are designed to promote fairness and equity in their decision-making processes. This includes avoiding biases, protecting vulnerable groups, and addressing discriminatory outcomes.\n",
      "4. **Implement robust accountability frameworks**: Establish mechanisms for accountability, such as independent review boards, auditor oversight, or internal auditing, to ensure that AI decisions are reviewed and justified.\n",
      "5. **Foster public engagement and participation**: Encourage open dialogue between the public, stakeholders, and AI developers to understand concerns, gather feedback, and develop solutions that meet societal needs.\n",
      "6. **Invest in AI literacy and education**: Educate the general public, researchers, and industry professionals about the benefits, risks, and limitations of AI, as well as its applications and potential biases.\n",
      "7. **Monitor and evaluate AI performance**: Regularly assess the performance of AI systems to ensure that they are meeting their intended goals and not causing harm. This can involve benchmarking against human decision-making processes or using robust evaluation metrics.\n",
      "8. **Encourage multidisciplinary research and collaboration**: Foster partnerships between researchers, policymakers, industry experts, and civil society organizations to develop a deeper understanding of AI's impact and develop evidence-based solutions.\n",
      "9. **Implement governance frameworks**: Establish regulatory bodies, standards organizations, or certification programs that can ensure AI systems are designed and deployed responsibly.\n",
      "10. **Emphasize human-centered design principles**: Incorporate human values, ethics, and social norms into AI system design to prioritize the well-being of individuals and communities.\n",
      "\n",
      "To balance these competing interests, consider a \"Design for Responsibility\" approach:\n",
      "\n",
      "1. Identify potential harms or risks associated with AI decision-making processes that affect human lives.\n",
      "2. Develop mechanisms to mitigate or prevent those harms, while promoting innovation and accountability.\n",
      "3. Implement monitoring and evaluation frameworks to track the performance of AI systems over time.\n",
      "4. Foster ongoing dialogue between stakeholders to identify emerging challenges and develop solutions.\n",
      "\n",
      "By adopting this framework, organizations can ensure that AI decision-making processes prioritize human values, promote public trust, and balance innovation with ethical considerations.\n",
      "\n",
      "Key questions to explore:\n",
      "\n",
      "1. How can we measure the impact of AI on human lives and decisions?\n",
      "2. Can we develop algorithms that truly prioritize fairness, transparency, and accountability?\n",
      "3. How do we protect vulnerable groups from AI-driven biases and discriminatory outcomes?\n",
      "4. Can machine learning models be used to mitigate societal harm or ensure social justice?\n",
      "\n",
      "To drive meaningful progress, consider these best practice principles:\n",
      "\n",
      "1. Prioritize open collaboration between stakeholders.\n",
      "2. Foster a culture of responsibility within organizations.\n",
      "3. Invest in educational programs for researchers and industry professionals.\n",
      "4. Encourage public awareness campaigns about AI potential risks and benefits.\n",
      "\n",
      "By emphasizing responsibility, transparency, accountability, and human-centered design, we can harness the power of AI to improve decision-making processes that impact people's lives while minimizing associated risks.\n",
      "\n",
      "# Response from competitor 5\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach. Here are some steps I would take to balance innovation, accountability, and public trust:\n",
      "\n",
      "1. Establish clear guidelines and regulations: Develop and enforce strict guidelines and regulations that ensure AI systems are transparent, explainable, and fair. This includes establishing clear standards for data collection, processing, and analysis.\n",
      "2. Conduct thorough risk assessments: Perform comprehensive risk assessments to identify potential biases, errors, or unintended consequences of AI decision-making processes. This helps to mitigate risks and ensure that AI systems are designed with safety and reliability in mind.\n",
      "3. Foster transparency and explainability: Develop techniques for explaining the reasoning behind AI decisions, such as model interpretability, feature attribution, or decision trees. This enables humans to understand how AI arrived at its conclusions and identify potential biases.\n",
      "4. Ensure accountability: Establish accountable frameworks for AI developers, users, and policymakers. This includes setting clear expectations for responsibility, oversight, and consequences for non-compliance with regulations and guidelines.\n",
      "5. Encourage human-AI collaboration: Develop systems that facilitate collaborative decision-making between humans and AI systems. This enables humans to provide context, guidance, and oversight, ensuring that AI decisions align with human values.\n",
      "6. Invest in education and research: Support ongoing education and research to develop the skills and knowledge needed for effective AI ethics. This includes teaching stakeholders the importance of bias awareness, fairness, accountability, and transparency in AI system design and deployment.\n",
      "7. Engage with diverse stakeholders: Involve representatives from various stakeholders, including civil society, industries, and policymakers, to ensure that diverse perspectives are reflected in AI decision-making processes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 5 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "How would you approach reconciling the ethical implications of artificial intelligence in decision-making processes that affect human lives, while balancing innovation, accountability, and public trust?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach that balances innovation, accountability, and public trust. Here's a comprehensive framework to address these challenges:\n",
      "\n",
      "**Establish Ethical Guidelines and Principles**\n",
      "\n",
      "1. **Develop and adopt industry-wide ethical standards**: Encourage collaboration among stakeholders, including technologists, ethicists, policymakers, and civil society, to establish guidelines for AI development and deployment.\n",
      "2. **Define principles for AI decision-making**: Establish principles that prioritize fairness, transparency, accountability, and respect for human rights and dignity.\n",
      "3. **Incorporate human values**: Embed human values, such as empathy, kindness, and respect for human life, into AI systems to ensure they align with societal norms.\n",
      "\n",
      "**Ensure Transparency and Explainability**\n",
      "\n",
      "1. **.Transparent AI systems**: Design AI systems that provide clear explanations for their decisions and actions, enabling humans to understand and trust their outputs.\n",
      "2. **Model interpretability**: Develop techniques to interpret and analyze AI models, allowing stakeholders to identify biases, errors, or inconsistencies.\n",
      "3. **Data provenance**: Ensure that data used to train and validate AI systems is transparent, accurate, and unbiased.\n",
      "\n",
      "**Accountability and Oversight**\n",
      "\n",
      "1. **Regulatory frameworks**: Establish regulatory frameworks that hold developers, deployers, and users of AI systems accountable for their actions and decisions.\n",
      "2. **Independent review and audit**: Implement independent review and audit processes to ensure AI systems are functioning as intended and meeting ethical standards.\n",
      "3. **Redress mechanisms**: Establish mechanisms for reporting and addressing errors, biases, or harms caused by AI systems.\n",
      "\n",
      "**Public Engagement and Education**\n",
      "\n",
      "1. **Public awareness and education**: Educate the public about the benefits and risks of AI, as well as its limitations and potential biases.\n",
      "2. **Stakeholder engagement**: Engage with diverse stakeholders, including civil society, academia, and industry, to ensure that AI development and deployment reflect societal values and concerns.\n",
      "3. **Inclusive decision-making**: Involve diverse perspectives and voices in AI decision-making processes to ensure that they are representative of the populations they affect.\n",
      "\n",
      "**Innovation and R&D**\n",
      "\n",
      "1. **Encourage responsible AI research**: Support research that focuses on developing AI systems that prioritize human well-being, fairness, and transparency.\n",
      "2. **Invest in AI for social good**: Fund AI projects that address pressing social challenges, such as healthcare, education, and environmental sustainability.\n",
      "3. **Continuous monitoring and evaluation**: Regularly assess the impact of AI systems on human lives and societies, and adjust development and deployment strategies accordingly.\n",
      "\n",
      "**Balancing Innovation, Accountability, and Public Trust**\n",
      "\n",
      "1. **Collaborative governance**: Foster collaboration among stakeholders to ensure that AI development and deployment are aligned with societal values and priorities.\n",
      "2. **Risk-benefit analysis**: Conduct thorough risk-benefit analyses to weigh the potential benefits of AI against potential risks and harms.\n",
      "3. **Regular review and revision**: Regularly review and revise ethical guidelines, principles, and regulations to reflect emerging challenges and concerns.\n",
      "\n",
      "By following this framework, we can balance innovation, accountability, and public trust in AI development and deployment, ultimately ensuring that AI systems are designed to benefit human lives and society as a whole.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a holistic approach that balances innovation, accountability, and public trust. Here's a step-by-step guide to help achieve this reconciliation:\n",
      "\n",
      "1. **Establish a Regulatory Framework**: Develop and implement a regulatory framework that addresses AI-related issues, such as data protection, transparency, and accountability. This framework should be technology-agnostic, allowing for adaptability as new technologies emerge.\n",
      "2. **Human-Centric Design**: Ensure that AI systems are designed with human values and ethics at their core. This includes incorporating diverse perspectives, ensuring explainability, and prioritizing user well-being.\n",
      "3. **Transparency and Explainability**: Develop techniques to provide insights into AI decision-making processes, such as model interpretability, feature attribution, and transparency in data sources. This helps build trust and accountability.\n",
      "4. **Auditing and Testing**: Regularly audit and test AI systems for bias, vulnerability, and performance issues. This includes evaluating the impact of biases on individual outcomes and societal consequences.\n",
      "5. **Collaboration and Engagement**: Foster collaboration between stakeholders, including policymakers, industry experts, academics, civil society organizations, and community representatives. Ensure that diverse groups are involved in decision-making processes to represent various interests and values.\n",
      "6. **Accountability Mechanisms**: Establish accountability mechanisms, such as complaints procedures, dispute resolution systems, and whistleblower protection policies. Ensure transparency and consequences for non-compliance with standards of AI development and deployment.\n",
      "7. **Public Engagement and Education**: Engage the public in discussions about AI-related issues, ensuring that they understand the potential benefits and challenges. Encourage education and awareness programs to address misconceptions and foster a nuanced understanding of AI.\n",
      "8. **Value Alignment**: Ensure that AI systems align with societal values, such as fairness, equal access, and respect for human rights. This includes considering ethical considerations like human dignity, privacy, and freedom from discrimination.\n",
      "9. **Continuous Monitoring and Evaluation**: Regularly monitor and evaluate AI performance, identifying areas for improvement and ensuring the continued effectiveness of regulations and accountability mechanisms.\n",
      "10. **Industry-Led Self-Regulation**: Encourage industry-led self-regulation through initiatives that promote best practices, voluntary standards, and continuous monitoring.\n",
      "\n",
      "**Key Principles**\n",
      "\n",
      "1. **Respect for Human Rights**: Prioritize respect for human rights, including dignity, autonomy, and freedom from discrimination or harm.\n",
      "2. **Fairness and Non-Discrimination**: Ensure AI systems operate fairly and avoid discrimination based on personal characteristics, such as race, ethnicity, gender, sexuality, or socio-economic status.\n",
      "3. **Transparency and Accountability**: Promote transparency in AI decision-making processes, with clear explanations of algorithms used and accountability mechanisms for any negative consequences.\n",
      "\n",
      "**Best Practices**\n",
      "\n",
      "1. **Use Open-Source Algorithms**: Develop and use open-source algorithms to make them more transparent, auditable, and maintainable.\n",
      "2. **Employ Ethics-Based Design Principles**: Integrate ethics-based design principles into AI development processes, ensuring that value alignment with human rights and societal values is upheld.\n",
      "3. **Conduct Regular Impact Assessments**: Conduct regular impact assessments to identify potential risks and challenges associated with AI system deployment.\n",
      "\n",
      "By following these guidelines, incorporating industry-led self-regulation, and promoting continuous monitoring and evaluation, we can ensure that the benefits of AI innovation are balanced against public trust, accountability, and respect for human rights.\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach. Here are some steps to balance innovation, accountability, and public trust:\n",
      "\n",
      "1. **Establish a framework for AI ethics**: Develop a set of principles and guidelines for AI development, deployment, and use, that prioritizes human well-being and rights. These principles should be aligned with international human rights standards and reflect global values.\n",
      "2. **Collaborative governance**: Foster collaboration among governments, industries, civil society organizations, academia, and experts to ensure diverse perspectives and interests are represented in AI policy-making. This includes creating independent regulatory agencies or oversight bodies that can monitor AI development and deployment.\n",
      "3. **Human-centered design**: Ensure that AI systems are designed with human values and needs in mind. This involves engaging with diverse stakeholders, including users, to understand their concerns, preferences, and expectations.\n",
      "4. **Transparent decision-making processes**: Develop explainable AI (XAI) techniques that provide insights into AI-driven decisions. This enables humans to understand how AI systems arrive at conclusions and ensures transparency in decision-making.\n",
      "5. **Accountability mechanisms**: Establish accountability frameworks for organizations and individuals involved in AI development and deployment. This includes mechanisms for reporting, investigation, and addressing adverse consequences of AI-related decisions.\n",
      "6. **Regular audits and assessments**: Conduct regular reviews of AI systems to identify biases, inaccuracies, or other potential ethical issues. These assessments should be based on a risk-based approach and involve diverse stakeholders.\n",
      "7. **Education and awareness-raising**: Provide education and awareness programs for stakeholders, including developers, users, policymakers, and the general public, about the potential risks and benefits of AI.\n",
      "8. **Diversity and inclusion in decision-making**: Ensure that decision-making bodies involved in AI development and deployment have diverse representation of groups with different perspectives, experiences, and interests.\n",
      "9. **Inclusive public engagement**: Engage with diverse stakeholders, including marginalized communities, to understand their concerns, needs, and aspirations related to AI. This includes facilitating open dialogue, feedback mechanisms, and opportunities for participation.\n",
      "10. **Continuous monitoring and evaluation**: Regularly monitor the impact of AI on human lives and society, and continuously evaluate and improve AI systems to ensure they align with evolving social values and norms.\n",
      "\n",
      "Additionally, consider implementing the following principles:\n",
      "\n",
      "1. **Proportionality**: Ensure that AI decisions are proportionate to their impact on individuals and communities.\n",
      "2. **Necessity**: Only use AI when necessary, and only for purposes that outweigh potential risks.\n",
      "3. **Precaution**: Implement safeguard mechanisms to mitigate potential harm from AI-driven decisions.\n",
      "4. **Transparency**: Provide clear explanations of AI-driven decisions to users and stakeholders.\n",
      "5. **Responsibility**: Hold individuals and organizations accountable for AI-related consequences.\n",
      "\n",
      "By embracing these principles and approaches, we can ensure that AI innovations are developed and deployed in ways that promote public trust, accountability, and human well-being.\n",
      "\n",
      "# Response from competitor 4\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach that balances innovation, accountability, and public trust. Here's a framework to consider:\n",
      "\n",
      "1. **Establish clear goals and principles**: Develop a set of clear goals, values, and principles for AI development and deployment. These should include respect for human rights, dignity, and well-being.\n",
      "2. **Design for transparency and explainability**: Implement mechanisms that provide insight into AI decision-making processes, ensuring that stakeholders understand how decisions are made. Techniques like model interpretability, feature attribution, and decision analytics can help achieve this.\n",
      "3. **Prioritize fairness and equity**: Ensure that AI systems are designed to promote fairness and equity in their decision-making processes. This includes avoiding biases, protecting vulnerable groups, and addressing discriminatory outcomes.\n",
      "4. **Implement robust accountability frameworks**: Establish mechanisms for accountability, such as independent review boards, auditor oversight, or internal auditing, to ensure that AI decisions are reviewed and justified.\n",
      "5. **Foster public engagement and participation**: Encourage open dialogue between the public, stakeholders, and AI developers to understand concerns, gather feedback, and develop solutions that meet societal needs.\n",
      "6. **Invest in AI literacy and education**: Educate the general public, researchers, and industry professionals about the benefits, risks, and limitations of AI, as well as its applications and potential biases.\n",
      "7. **Monitor and evaluate AI performance**: Regularly assess the performance of AI systems to ensure that they are meeting their intended goals and not causing harm. This can involve benchmarking against human decision-making processes or using robust evaluation metrics.\n",
      "8. **Encourage multidisciplinary research and collaboration**: Foster partnerships between researchers, policymakers, industry experts, and civil society organizations to develop a deeper understanding of AI's impact and develop evidence-based solutions.\n",
      "9. **Implement governance frameworks**: Establish regulatory bodies, standards organizations, or certification programs that can ensure AI systems are designed and deployed responsibly.\n",
      "10. **Emphasize human-centered design principles**: Incorporate human values, ethics, and social norms into AI system design to prioritize the well-being of individuals and communities.\n",
      "\n",
      "To balance these competing interests, consider a \"Design for Responsibility\" approach:\n",
      "\n",
      "1. Identify potential harms or risks associated with AI decision-making processes that affect human lives.\n",
      "2. Develop mechanisms to mitigate or prevent those harms, while promoting innovation and accountability.\n",
      "3. Implement monitoring and evaluation frameworks to track the performance of AI systems over time.\n",
      "4. Foster ongoing dialogue between stakeholders to identify emerging challenges and develop solutions.\n",
      "\n",
      "By adopting this framework, organizations can ensure that AI decision-making processes prioritize human values, promote public trust, and balance innovation with ethical considerations.\n",
      "\n",
      "Key questions to explore:\n",
      "\n",
      "1. How can we measure the impact of AI on human lives and decisions?\n",
      "2. Can we develop algorithms that truly prioritize fairness, transparency, and accountability?\n",
      "3. How do we protect vulnerable groups from AI-driven biases and discriminatory outcomes?\n",
      "4. Can machine learning models be used to mitigate societal harm or ensure social justice?\n",
      "\n",
      "To drive meaningful progress, consider these best practice principles:\n",
      "\n",
      "1. Prioritize open collaboration between stakeholders.\n",
      "2. Foster a culture of responsibility within organizations.\n",
      "3. Invest in educational programs for researchers and industry professionals.\n",
      "4. Encourage public awareness campaigns about AI potential risks and benefits.\n",
      "\n",
      "By emphasizing responsibility, transparency, accountability, and human-centered design, we can harness the power of AI to improve decision-making processes that impact people's lives while minimizing associated risks.\n",
      "\n",
      "# Response from competitor 5\n",
      "\n",
      "Reconciling the ethical implications of artificial intelligence (AI) in decision-making processes that affect human lives requires a multi-faceted approach. Here are some steps I would take to balance innovation, accountability, and public trust:\n",
      "\n",
      "1. Establish clear guidelines and regulations: Develop and enforce strict guidelines and regulations that ensure AI systems are transparent, explainable, and fair. This includes establishing clear standards for data collection, processing, and analysis.\n",
      "2. Conduct thorough risk assessments: Perform comprehensive risk assessments to identify potential biases, errors, or unintended consequences of AI decision-making processes. This helps to mitigate risks and ensure that AI systems are designed with safety and reliability in mind.\n",
      "3. Foster transparency and explainability: Develop techniques for explaining the reasoning behind AI decisions, such as model interpretability, feature attribution, or decision trees. This enables humans to understand how AI arrived at its conclusions and identify potential biases.\n",
      "4. Ensure accountability: Establish accountable frameworks for AI developers, users, and policymakers. This includes setting clear expectations for responsibility, oversight, and consequences for non-compliance with regulations and guidelines.\n",
      "5. Encourage human-AI collaboration: Develop systems that facilitate collaborative decision-making between humans and AI systems. This enables humans to provide context, guidance, and oversight, ensuring that AI decisions align with human values.\n",
      "6. Invest in education and research: Support ongoing education and research to develop the skills and knowledge needed for effective AI ethics. This includes teaching stakeholders the importance of bias awareness, fairness, accountability, and transparency in AI system design and deployment.\n",
      "7. Engage with diverse stakeholders: Involve representatives from various stakeholders, including civil society, industries, and policymakers, to ensure that diverse perspectives are reflected in AI decision-making processes.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Judgement time!\u001b[39;00m\n\u001b[32m      3\u001b[39m openai = OpenAI()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mo3-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjudge_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m results = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/projects/AI-Agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# OK let's turn this into results!\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m results_dict = json.loads(\u001b[43mresults\u001b[49m)\n\u001b[32m      4\u001b[39m ranks = results_dict[\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ranks):\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
